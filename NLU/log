I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 960
major: 5 minor: 2 memoryClockRate (GHz) 1.266
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.58GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 6261 get requests, put_count=6181 evicted_count=1000 eviction_rate=0.161786 and unsatisfied allocation rate=0.188468
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
End of epoch 1 : training loss = 8.13999
End of epoch 2 : training loss = 6.02855
End of epoch 3 : training loss = 4.26337
End of epoch 4 : training loss = 3.36294
End of epoch 5 : training loss = 2.39052
End of epoch 6 : training loss = 1.69778
End of epoch 7 : training loss = 1.43272
End of epoch 8 : training loss = 1.01363
End of epoch 9 : training loss = 0.795034
End of epoch 10 : training loss = 0.553428
End of epoch 11 : training loss = 0.446468
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1197273 get requests, put_count=1197286 evicted_count=1000 eviction_rate=0.000835222 and unsatisfied allocation rate=0.000843584
End of epoch 12 : training loss = 0.393422
End of epoch 13 : training loss = 0.283704
End of epoch 14 : training loss = 0.25924
End of epoch 15 : training loss = 0.265676
End of epoch 16 : training loss = 0.18037
End of epoch 17 : training loss = 0.139894
End of epoch 18 : training loss = 0.189215
End of epoch 19 : training loss = 0.0991096
End of epoch 20 : training loss = 0.0863013
End of epoch 21 : training loss = 0.0725549
End of epoch 22 : training loss = 0.0716669
End of epoch 23 : training loss = 0.0574363
End of epoch 24 : training loss = 0.0600229
End of epoch 25 : training loss = 0.0407472
End of epoch 26 : training loss = 0.0397834
End of epoch 27 : training loss = 0.0466441
End of epoch 28 : training loss = 0.027551
End of epoch 29 : training loss = 0.0238837
End of epoch 30 : training loss = 0.0214234
Model saved in file:./NLU/model/model.ckpt-30

real	2m27.963s
user	2m35.440s
sys	0m19.564s
